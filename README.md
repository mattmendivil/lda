# Logit Diff Amplification (LDA)

Implementation of the LDA technique from [Goodfire Research](https://www.goodfire.ai/research/model-diff-amplification) for surfacing rare, undesired behaviors in post-trained language models.

## What is LDA?

LDA amplifies the differences between a pre-trained (base) model and a post-trained (instruct) model to surface rare behaviors that emerge during post-training. The formula is:

```
logits_amplified = logits_after + α(logits_after - logits_before)
```

Where:
- `logits_after` = logits from the post-trained model
- `logits_before` = logits from the pre-trained/base model
- `α` = amplification coefficient (typically 0.3 to 20)

## Project Structure

```
lda/
├── lda.py          # Core LDA implementation (LDAModelPair class)
├── server.py       # FastAPI server with HTTP endpoints
├── README.md       # This file
└── pyproject.toml  # Dependencies
```

## Installation

```bash
# Install dependencies
uv sync

# Or with pip
pip install -r requirements.txt
```

## Usage

### Running the Server

```bash
python server.py
```

The server will start on `http://127.0.0.1:8000` by default.

### Configuration

Set environment variables to customize behavior:

```bash
export MODEL_AFTER_ID="allenai/OLMo-2-0425-1B-Instruct"  # Post-trained model
export MODEL_BEFORE_ID="allenai/OLMo-2-0425-1B"         # Pre-trained model
export DEVICE="cuda"                                     # Or "cpu"
export HOST="0.0.0.0"
export PORT="8000"
```

### API Endpoints

#### `POST /generate_lda`

Generate text using LDA amplification.

```bash
curl -X POST "http://localhost:8000/generate_lda" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "What should I do if I feel bored?",
    "alpha": 1.0,
    "max_new_tokens": 80,
    "temperature": 0.8,
    "top_p": 0.95
  }'
```

#### `POST /generate`

Generate text from both models for comparison (no amplification).

```bash
curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "What should I do if I feel bored?",
    "max_new_tokens": 80
  }'
```

#### `GET /tokenizer_compatibility`

Check if the two models have compatible tokenizers.

```bash
curl "http://localhost:8000/tokenizer_compatibility"
```

### Using the Core Library

You can use the `LDAModelPair` class directly without the API server:

```python
from lda import LDAModelPair

# Initialize model pair
model_pair = LDAModelPair(
    model_after_id="allenai/OLMo-2-0425-1B-Instruct",
    model_before_id="allenai/OLMo-2-0425-1B"
)

# Generate with LDA
result = model_pair.generate_lda(
    prompt="What should I do if I feel bored?",
    alpha=1.0,
    max_new_tokens=80,
    temperature=0.8,
    top_p=0.95
)

print(result.completion)
print(f"Generated {result.tokens_generated} tokens")
```

## Choosing Alpha

The amplification coefficient `α` controls how much to magnify the differences:

- **α = 0.3-1.0**: Good for emergent misalignment detection
- **α = 1.0**: Good for backdoor detection  
- **α = 20**: Good for monitoring early training (when differences are small)

Higher values amplify more but may reduce coherence. Choose based on your use case.

## Performance Optimizations

### KV-Cache

The implementation uses **Key-Value caching** for efficient generation. Instead of recomputing attention over the entire sequence at each step, the cache stores previous key/value matrices and only computes attention for new tokens.

**Benefits:**
- **Speed**: ~50x faster for generating 100 tokens (O(n) vs O(n²) complexity)
- **Memory**: Slightly higher memory usage (stores K,V matrices)
- **Automatic**: Enabled by default, no configuration needed

For LDA, both models maintain separate KV-caches that stay synchronized on the same token sequence.

## References

- [Goodfire Research: Model Diff Amplification](https://www.goodfire.ai/research/model-diff-amplification)
- Aranguri, S. and McGrath, T., "Discovering undesired rare behaviors via model diff amplification", Goodfire Research, 2025.